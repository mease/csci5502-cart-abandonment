{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4bc8937",
   "metadata": {},
   "source": [
    "## Shopping Cart Abandonment\n",
    "## Transformer\n",
    "Code References:\n",
    "\n",
    "https://www.tensorflow.org/text/tutorials/transformer\n",
    "\n",
    "https://medium.com/@max_garber/simple-keras-transformer-model-74724a83bb83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a220c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/mease/csci5502-cart-abandonment/raw/main/data/cart_abandon_data_seq_30.zip\n",
    "!mkdir data\n",
    "!unzip cart_abandon_data_seq_30.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82ab37aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "try:\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Layer, Add, MultiHeadAttention, GlobalAveragePooling1D, Conv1D, Input, Embedding, Concatenate, LayerNormalization, Dense, Dropout\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1c72f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/X_train.npy', 'rb') as f:\n",
    "    X_train = np.load(f)\n",
    "with open('data/y_train.npy', 'rb') as f:\n",
    "    y_train = np.load(f)\n",
    "with open('data/X_test.npy', 'rb') as f:\n",
    "    X_test = np.load(f)\n",
    "with open('data/y_test.npy', 'rb') as f:\n",
    "    y_test = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5946947d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time vocab: 4369, Item vocab: 51758, Category vocab: 335\n"
     ]
    }
   ],
   "source": [
    "time_vocab_size = len(np.unique(np.concatenate((np.unique(X_train[:,:,0]),np.unique(X_test[:,:,0])))))\n",
    "item_vocab_size = len(np.unique(np.concatenate((np.unique(X_train[:,:,1]),np.unique(X_test[:,:,1])))))\n",
    "cat_vocab_size = len(np.unique(np.concatenate((np.unique(X_train[:,:,2]),np.unique(X_test[:,:,2])))))\n",
    "print(f\"Time vocab: {time_vocab_size}, Item vocab: {item_vocab_size}, Category vocab: {cat_vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0f02c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "698d01ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, enc_len, seq_len, name=None):\n",
    "        super(PositionalEncoding, self).__init__(name=name)\n",
    "\n",
    "        self.enc_len = enc_len\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        angle_rads = self.get_angles(np.arange(self.seq_len)[:, np.newaxis],\n",
    "                                     np.arange(self.enc_len)[np.newaxis, :])\n",
    "\n",
    "        # apply sin to even indices in the array; 2i\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "        # apply cos to odd indices in the array; 2i+1\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        self.pos_encoding = angle_rads[np.newaxis, ...]\n",
    "        self.pos_encoding = tf.cast(self.pos_encoding, dtype=tf.float32)\n",
    "    \n",
    "    def get_angles(self, pos, i):\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(self.enc_len))\n",
    "        return pos * angle_rates\n",
    "    \n",
    "    def call(self, x, training, mask=None):\n",
    "        x *= tf.math.sqrt(tf.cast(self.enc_len, tf.float32))\n",
    "        x += self.pos_encoding[:, :self.seq_len, :]\n",
    "        return x\n",
    "    \n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f1f622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, enc_len, num_heads, head_size, ff_dim, dropout=0, name=None):\n",
    "        super(TransformerEncoder, self).__init__(name=name)\n",
    "        self.ln1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.mha = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)\n",
    "        self.drop1 = Dropout(dropout)\n",
    "        self.ln2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.ff1 = Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")\n",
    "        self.drop2 = Dropout(dropout)\n",
    "        self.ff2 = Conv1D(filters=enc_len, kernel_size=1)\n",
    "\n",
    "    def call(self, x, training, mask=None):\n",
    "        inputs = x\n",
    "        x = self.ln1(x)\n",
    "        x = self.mha(x, x)\n",
    "        x = self.drop1(x)\n",
    "        res = x + inputs\n",
    "        x = self.ln2(res)\n",
    "        x = self.ff1(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.ff2(x)\n",
    "        x = x + res\n",
    "        return x\n",
    "    \n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c57e194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_heads = 4            # Number of attention heads\n",
    "head_size = 256          # Attention head size\n",
    "ff_dim = 4               # Encoder feed-forward size\n",
    "enc_dropout = 0.1        # Encoder dropout\n",
    "out_linear_size = 256    # Linear output layer size\n",
    "out_linear_dropout = 0.1 # Linear output layer dropout\n",
    "encoder_layers = 3       # Number of transformer encoder layers\n",
    "learning_rate = 1e-3     # Optimizer learning rate\n",
    "batch_size = 1024        # Training batch size\n",
    "epochs = 3               # Number of epochs to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdfee8b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " time_input (InputLayer)        [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " item_input (InputLayer)        [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " category_input (InputLayer)    [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " time_embedding (Embedding)     (None, 30, 10)       43690       ['time_input[0][0]']             \n",
      "                                                                                                  \n",
      " item_embedding (Embedding)     (None, 30, 100)      5175800     ['item_input[0][0]']             \n",
      "                                                                                                  \n",
      " category_embedding (Embedding)  (None, 30, 10)      3350        ['category_input[0][0]']         \n",
      "                                                                                                  \n",
      " concat_embeddings (Concatenate  (None, 30, 120)     0           ['time_embedding[0][0]',         \n",
      " )                                                                'item_embedding[0][0]',         \n",
      "                                                                  'category_embedding[0][0]']     \n",
      "                                                                                                  \n",
      " pos_encoding (PositionalEncodi  (None, 30, 120)     0           ['concat_embeddings[0][0]']      \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " encoder_1 (TransformerEncoder)  (None, 30, 120)     496276      ['pos_encoding[0][0]']           \n",
      "                                                                                                  \n",
      " encoder_2 (TransformerEncoder)  (None, 30, 120)     496276      ['encoder_1[0][0]']              \n",
      "                                                                                                  \n",
      " encoder_3 (TransformerEncoder)  (None, 30, 120)     496276      ['encoder_2[0][0]']              \n",
      "                                                                                                  \n",
      " pooling (GlobalAveragePooling1  (None, 120)         0           ['encoder_3[0][0]']              \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " linear_1 (Dense)               (None, 256)          30976       ['pooling[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 256)          0           ['linear_1[0][0]']               \n",
      "                                                                                                  \n",
      " linear_2 (Dense)               (None, 1)            257         ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,742,901\n",
      "Trainable params: 6,742,901\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Timestamp input and embedding\n",
    "time_inp = Input(shape=(sequence_length,), name='time_input')\n",
    "time_emb = Embedding(output_dim=10,\n",
    "                     input_dim=time_vocab_size,\n",
    "                     input_length=sequence_length,\n",
    "                     embeddings_initializer=tf.keras.initializers.RandomUniform(minval=-0.075, maxval=0.075),\n",
    "                     mask_zero=True,\n",
    "                     name='time_embedding')(time_inp)\n",
    "\n",
    "# Item ID input and embedding\n",
    "item_inp = Input(shape=(sequence_length,), name='item_input')\n",
    "item_emb = Embedding(output_dim=100,\n",
    "                     input_dim=item_vocab_size,\n",
    "                     input_length=sequence_length,\n",
    "                     embeddings_initializer=tf.keras.initializers.RandomUniform(minval=-0.075, maxval=0.075),\n",
    "                     mask_zero=True,\n",
    "                     name='item_embedding')(item_inp)\n",
    "\n",
    "# Category input and embedding\n",
    "cat_inp = Input(shape=(sequence_length,), name='category_input')\n",
    "cat_emb = Embedding(output_dim=10,\n",
    "                    input_dim=cat_vocab_size,\n",
    "                    input_length=sequence_length,\n",
    "                    embeddings_initializer=tf.keras.initializers.RandomUniform(minval=-0.075, maxval=0.075),\n",
    "                    mask_zero=True,\n",
    "                    name='category_embedding')(cat_inp)\n",
    "\n",
    "# Concatenate embeddings\n",
    "embedding = Concatenate(axis=2, name='concat_embeddings')([time_emb, item_emb, cat_emb])\n",
    "\n",
    "x = PositionalEncoding(enc_len=embedding.shape[-1],\n",
    "                       seq_len=sequence_length,\n",
    "                       name='pos_encoding')(embedding)\n",
    "\n",
    "# Transformer Encoder layers\n",
    "for i in range(encoder_layers):\n",
    "    x = TransformerEncoder(enc_len=embedding.shape[-1],\n",
    "                           num_heads=num_heads,\n",
    "                           head_size=head_size,\n",
    "                           ff_dim=ff_dim,\n",
    "                           dropout=enc_dropout,\n",
    "                           name=f\"encoder_{i+1}\")(x)\n",
    "\n",
    "x = GlobalAveragePooling1D(name='pooling')(x)\n",
    "x = Dense(out_linear_size, activation=\"relu\", name='linear_1')(x)\n",
    "x = Dropout(out_linear_dropout)(x)\n",
    "out = Dense(1, activation=\"sigmoid\", name='linear_2')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=[time_inp, item_inp, cat_inp], outputs=[out])\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "              metrics=[keras.metrics.TruePositives(name='tp'),\n",
    "                       keras.metrics.FalsePositives(name='fp'),\n",
    "                       keras.metrics.TrueNegatives(name='tn'),\n",
    "                       keras.metrics.FalseNegatives(name='fn'),\n",
    "                       keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                       keras.metrics.Precision(name='precision'),\n",
    "                       keras.metrics.Recall(name='recall'),\n",
    "                       keras.metrics.AUC(name='auc')])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fbb1489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7209/7209 [==============================] - 2057s 284ms/step - loss: 0.1788 - tp: 5741.0000 - fp: 6470.0000 - tn: 6972773.0000 - fn: 396871.0000 - accuracy: 0.9454 - precision: 0.4701 - recall: 0.0143 - auc: 0.7939 - val_loss: 0.1745 - val_tp: 2001.0000 - val_fp: 1668.0000 - val_tn: 1743143.0000 - val_fn: 98652.0000 - val_accuracy: 0.9456 - val_precision: 0.5454 - val_recall: 0.0199 - val_auc: 0.8119\n",
      "Epoch 2/3\n",
      "7209/7209 [==============================] - 2052s 285ms/step - loss: 0.1708 - tp: 11273.0000 - fp: 9446.0000 - tn: 6969797.0000 - fn: 391339.0000 - accuracy: 0.9457 - precision: 0.5441 - recall: 0.0280 - auc: 0.8242 - val_loss: 0.1729 - val_tp: 3115.0000 - val_fp: 2742.0000 - val_tn: 1742069.0000 - val_fn: 97538.0000 - val_accuracy: 0.9457 - val_precision: 0.5318 - val_recall: 0.0309 - val_auc: 0.8200\n",
      "Epoch 3/3\n",
      "7209/7209 [==============================] - 2053s 285ms/step - loss: 0.1663 - tp: 18091.0000 - fp: 14435.0000 - tn: 6964808.0000 - fn: 384521.0000 - accuracy: 0.9460 - precision: 0.5562 - recall: 0.0449 - auc: 0.8388 - val_loss: 0.1723 - val_tp: 3842.0000 - val_fp: 3590.0000 - val_tn: 1741221.0000 - val_fn: 96811.0000 - val_accuracy: 0.9456 - val_precision: 0.5170 - val_recall: 0.0382 - val_auc: 0.8205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x202bba5a370>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    [X_train[:,:,0], X_train[:,:,1], X_train[:,:,2]], y_train,\n",
    "    validation_data=([X_test[:,:,0], X_test[:,:,1], X_test[:,:,2]], y_test),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7190051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict([X_test[:,:,0], X_test[:,:,1], X_test[:,:,2]])\n",
    "y_pred = (prediction > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01590748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9473    0.9979    0.9720   1744811\n",
      "           1     0.5170    0.0382    0.0711    100653\n",
      "\n",
      "    accuracy                         0.9456   1845464\n",
      "   macro avg     0.7321    0.5181    0.5215   1845464\n",
      "weighted avg     0.9239    0.9456    0.9228   1845464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, digits=4, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6656f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.ylabel(\"Actual label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.title(\"Transformer Classifier\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
